{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba9dcf02-249d-42fa-bd18-ec17ebc43a61",
   "metadata": {},
   "source": [
    "# 配置信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bb64646-b38d-42ed-b627-dabc7d95765c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer, BitsAndBytesConfig\n",
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "model_name_or_path = '/home/abc/mydisk/model/chatglm3-6b'  # 模型路径\n",
    "peft_model_path = \"/home/abc/mydisk/model/chatglm3-6b/out_zhouyi/checkpoint-200/\"  # 微调模型路径\n",
    "training_tag=\"ChatGLM3-6B(checkpoint-200, train_loss≈0.0006，数据集小，可能过拟合)\" # 微调情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf262144-13f2-4ec0-93eb-c0231dbfd283",
   "metadata": {},
   "outputs": [],
   "source": [
    "_compute_dtype_map = {\n",
    "    'fp32': torch.float32,\n",
    "    'fp16': torch.float16,\n",
    "    'bf16': torch.bfloat16\n",
    "}\n",
    "\n",
    "# QLoRA 量化配置\n",
    "q_config = BitsAndBytesConfig(load_in_4bit=True,\n",
    "                              bnb_4bit_quant_type='nf4',\n",
    "                              bnb_4bit_use_double_quant=True,\n",
    "                              bnb_4bit_compute_dtype=_compute_dtype_map['bf16'])\n",
    "\n",
    "config = PeftConfig.from_pretrained(peft_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77582f28-47d9-49f3-bcfc-d6d95e929a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a811d42b7ce4d4aadaf3cd6e2d91af7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting eos_token is not supported, use the default one.\n",
      "Setting pad_token is not supported, use the default one.\n",
      "Setting unk_token is not supported, use the default one.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatGLMForConditionalGeneration(\n",
       "  (transformer): ChatGLMModel(\n",
       "    (embedding): Embedding(\n",
       "      (word_embeddings): Embedding(65024, 4096)\n",
       "    )\n",
       "    (rotary_pos_emb): RotaryEmbedding()\n",
       "    (encoder): GLMTransformer(\n",
       "      (layers): ModuleList(\n",
       "        (0-27): 28 x GLMBlock(\n",
       "          (input_layernorm): RMSNorm()\n",
       "          (self_attention): SelfAttention(\n",
       "            (query_key_value): lora.Linear4bit(\n",
       "              (base_layer): Linear4bit(in_features=4096, out_features=4608, bias=True)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.05, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=16, out_features=4608, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (core_attention): CoreAttention(\n",
       "              (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (dense): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (post_attention_layernorm): RMSNorm()\n",
       "          (mlp): MLP(\n",
       "            (dense_h_to_4h): Linear4bit(in_features=4096, out_features=27392, bias=False)\n",
       "            (dense_4h_to_h): Linear4bit(in_features=13696, out_features=4096, bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layernorm): RMSNorm()\n",
       "    )\n",
       "    (output_layer): Linear(in_features=4096, out_features=65024, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载模型，tokenizer\n",
    "base_model = AutoModel.from_pretrained(model_name_or_path,\n",
    "                                      quantization_config=q_config,\n",
    "                                      device_map='auto',\n",
    "                                      trust_remote_code=True)\n",
    "\n",
    "qlora_model = PeftModel.from_pretrained(base_model, peft_model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, trust_remote_code=True)\n",
    "\n",
    "base_model.requires_grad_(False)\n",
    "base_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31c7abc3-d2c2-4fb2-b645-b64e7276baa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jul 10 23:02:46 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A10                     Off |   00000000:00:08.0 Off |                    0 |\n",
      "|  0%   43C    P0             58W /  150W |    4320MiB /  23028MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      1902      G   /usr/lib/xorg/Xorg                              4MiB |\n",
      "|    0   N/A  N/A     21740      C   /usr/bin/python3                             4298MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7321ee03-c19b-4d10-b010-51b1bc11b77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 比较方法，比较微调前后的结果\n",
    "def compare_chatglm_results(query, base_model, qlora_model, training_tag):\n",
    "    base_response, base_history = base_model.chat(tokenizer, query)\n",
    "\n",
    "    inputs = tokenizer(query, return_tensors=\"pt\").to(0)\n",
    "    ft_out = qlora_model.generate(**inputs, max_new_tokens=512)\n",
    "    ft_response = tokenizer.decode(ft_out[0], skip_special_tokens=True)\n",
    "    \n",
    "    print(f\"问题：{query}\\n\\n原始输出：\\n{base_response}\\n\\n\\n微调后（{training_tag}）：\\n{ft_response}\")\n",
    "    return base_response, ft_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8821df-6b57-44c4-ae50-2678be44959b",
   "metadata": {},
   "source": [
    "# 开始比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f070b2b-7ef4-4f77-adea-b42081d92ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "问题：周易中包含哪些卦象\n",
      "\n",
      "原始输出：\n",
      "在周易中，卦象是由两个卦象叠加而成，一个在上，一个在下，形成一种特定的卦象。一共有64卦，其中，坎卦、乾卦、坤卦被称为三大卦，其余的32卦都是通过叠加两个卦象而形成的。每一卦都有其特定的含义和哲学，涉及到天地人之间的关系。在周易中，卦象的解释和理解是非常重要的，它直接关系到对卦象的解读和应对。\n",
      "\n",
      "\n",
      "微调后（ChatGLM3-6B(checkpoint-200, train_loss≈0.0006，数据集小，可能过拟合)）：\n",
      "[gMASK] sop 周易中包含哪些卦象？ 在周易中，共有64卦，分为两个大卦：奇数卦和偶数卦。奇数卦包括奇数位数的卦象，如乾、奇数位的坤、奇数位的震、奇数位的巽、奇数位的坎、奇数位的离，以及奇数位的艮。偶数卦则包括偶数位数的卦象，如偶数位次的坤、偶数位次的震、偶数位次的巽、偶数位次的坎、偶数位次的离，以及偶数位次的艮。 \n",
      "\n",
      "在周易中，每一卦都有其独特的含义和象征，每一卦也都有不同的名字和卦象。这些卦象和名字都包含了宇宙的哲学和人生智慧，对于解读人生和解决困难都有重要的指导意义。\n"
     ]
    }
   ],
   "source": [
    "base_response, ft_response = compare_chatglm_results(\"周易中包含哪些卦象\", base_model, qlora_model, training_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d4b74f3-513d-4c5f-b7e4-8095e4cb260b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "问题：乾卦和坤卦一般代表什么\n",
      "\n",
      "原始输出：\n",
      "在周易中，乾卦和坤卦是两个最基本的卦象，它们分别代表不同的卦义。\n",
      "\n",
      "乾卦是由三个阳爻组成，象征着天，代表着正义、刚健和希望。它象征着天地的真理，强调刚健正义，希望获得吉祥。乾卦的卦象是天卦，代表着天地之德，以及君子观者之象。乾卦的卦象是一个卦象，由两个卦象叠加而成，上卦是乾，下卦是坤。乾卦代表天，坤卦代表地。\n",
      "\n",
      "坤卦是由三个阴爻组成，象征着地，它代表刚健、正派和无私。坤卦象征着天地之厚，以及君子观者之象。坤卦的卦象是一个卦象，由两个卦象叠加而成，上卦是坤，下卦是坤。坤卦代表地，代表着刚健、正派和无私。\n",
      "\n",
      "乾卦和坤卦在周易中具有很高的地位，它们分别代表不同的卦义，并且相互依存，相互制约。在解读乾卦和坤卦时，需要综合考虑，方能准确地理解其卦象所代表的意义。在个人成长和人生道路中，乾卦和坤卦分别代表着正义、刚健和正义、无私的品质，它们都是成长过程中必须拥有的品质。\n",
      "\n",
      "\n",
      "微调后（ChatGLM3-6B(checkpoint-200, train_loss≈0.0006，数据集小，可能过拟合)）：\n",
      "[gMASK] sop 乾卦和坤卦一般代表什么 乾卦和坤卦是周易中的两个卦象，分别由六个阳爻和六个阴爻组成。在周易中，卦象代表着宇宙的运行和变化，以及人类社会的现状和未来。乾卦和坤卦分别代表着天和地，象征着它们的不同特性和相互关系。\n",
      "\n",
      "乾卦由六个阳爻组成，象征着天，象征着刚健、健行、刚健不屈的意境。乾卦代表天，象征刚健、健行，以及不屈不挠的精神。乾卦的核心哲学是：天行健，君子拟之。意思是要像天行健一样，坚强不屈，努力奋斗。乾卦的象征意义包括：刚健、健行、刚健不屈。\n",
      "\n",
      "坤卦由六个阴爻组成，象征着地，象征着顺从、适应、包容的品德。坤卦代表地，象征着柔顺、和缓、包容，以及柔顺接受、适应环境的变化。坤卦的核心哲学是：地地相应，君子慎独。 meaning: 像地一样柔顺、包容，独自承担责任。坤卦的象征意义包括：和顺、和缓、包容，以及柔顺接受、适应环境的变化。\n",
      "\n",
      "乾卦和坤卦在周易中相互对应，象征着天地相互依存，相互补足，形成一种和谐的关系。在个人成长中，乾卦和坤卦分别代表着刚健和柔顺的品质，象征着要刚柔并济，才能实现事业成功和人生幸福。在事业和经商中，乾卦和坤卦分别代表着刚健和柔顺的品质，象征着事业的发展和人际关系的处理需要刚柔并济，才能实现成功。在婚恋和决策中，乾卦和坤卦分别代表着刚健和柔顺的品质，象征着婚恋的真诚和决策的谨慎，需要刚柔并济，才能实现幸福。\n"
     ]
    }
   ],
   "source": [
    "base_response, ft_response = compare_chatglm_results(\"乾卦和坤卦一般代表什么\", base_model, qlora_model, training_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6faf37a1-0b70-4851-bb37-e5891024038b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "问题：你知道水雷屯卦么\n",
      "\n",
      "原始输出：\n",
      "水雷屯卦是一个由雷卦和屯卦组成的卦象，它代表着雷雷屯屯，即雷声在晴天中屯聚不散，预示着天气将雷雷屯聚，即将有雷雨天气。在这里，屯卦代表待，即等待，意味着君子应当等待时机的到来，然后采取行动。因此，这个卦象预示着君子应当耐心等待时机的到来，宜迟行。\n",
      "\n",
      "\n",
      "微调后（ChatGLM3-6B(checkpoint-200, train_loss≈0.0006，数据集小，可能过拟合)）：\n",
      "[gMASK] sop 你知道水雷屯卦么? 当然知道，水雷屯卦是一个由雷卦和坎卦组成的卦象，它象征着雷击坎，表示危险和困难。在这个卦象中，君子应当警惕并避免锋芒所指，从而避免灾难。对于经商者，必须小心谨慎，避免轻举妄动，灵活变通，才能化险为夷。\n"
     ]
    }
   ],
   "source": [
    "base_response, ft_response = compare_chatglm_results(\"你知道水雷屯卦么\", base_model, qlora_model, training_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9043e53c-12d0-472b-865c-f08257ebd802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "问题：你认为周易的卦象都合理么\n",
      "\n",
      "原始输出：\n",
      "周易卦象是一种古老的占卜方式，它通过卦象的组合来揭示未来的吉凶。周易一卦分为两个部分，上卦和下卦，分别代表不同的卦象。通过卦象的组合，我们可以得出卦象的卦辞，从而得知这个卦象的吉祥或不吉祥。\n",
      "\n",
      "在周易中，每个卦象都有其独特的含义和象征。比如，乾卦代表天，坤卦代表地，而其他卦象则分别代表不同的自然现象，如雷、风、雨等。通过卦象的组合，我们可以得出卦象的卦辞，从而得知这个卦象的吉祥或不吉祥。\n",
      "\n",
      "虽然周易的卦象和卦辞都是古老的，但是它们仍然具有很高的参考价值。在现代，许多人会将周易的卦象和卦辞用于决策、预测和分析。然而，需要注意的是，周易的卦象和卦辞只是一种象征和参考，并不能完全决定未来的吉凶。因此，在运用周易卦象时，需要综合考虑卦象、卦辞、卦象的组合以及卦象的時运等因素。\n",
      "\n",
      "\n",
      "微调后（ChatGLM3-6B(checkpoint-200, train_loss≈0.0006，数据集小，可能过拟合)）：\n",
      "[gMASK] sop 你认为周易的卦象都合理么? 作为人工智能助手，我会根据我所学的知识来回答你的问题。\n",
      "周易是一部古老的占卜卦象，它由八卦组合而成，一共有64卦。每一卦都有不同的含义和象征，它们分别代表了不同的象数、卦辞和卦象。周易的主要目的是预测事物的发展和变化，指导人们的行为。\n",
      "\n",
      "虽然周易中的卦象和卦辞在古代被广泛应用于占卜和决策，但是随着时代的推移，人们对周易的理解和应用也产生了不同的观点和看法。有些人认为周易是迷信和伪科学，而另一些人则认为周易中蕴含着深刻的哲学和人生智慧。\n",
      "\n",
      "无论如何，周易作为一部古老的占卜卦象，它反映了古人对自然和社会现象的观察和理解，也反映了古人的人生哲学和价值观。虽然现代社会已经不再像古代那样依赖占卜来预测未来，但周易仍然可以作为一种思考和决策的参考，帮助人们更好地理解自己和周围的世界。\n"
     ]
    }
   ],
   "source": [
    "base_response, ft_response = compare_chatglm_results(\"你认为周易的卦象都合理么\", base_model, qlora_model, training_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18be8c2f-56dc-4de7-a9b2-838458bd4153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jul 10 23:12:52 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A10                     Off |   00000000:00:08.0 Off |                    0 |\n",
      "|  0%   45C    P0             59W /  150W |    4852MiB /  23028MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      1902      G   /usr/lib/xorg/Xorg                              4MiB |\n",
      "|    0   N/A  N/A     21740      C   /usr/bin/python3                             4830MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a784ff-caba-49c2-89c9-2d557e2b249b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
